{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ParlAI \"tutorial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n",
      "** fvcore version of PathManager will be deprecated soon. **\n",
      "** Please migrate to the version in iopath repo. **\n",
      "https://github.com/facebookresearch/iopath \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from parlai.core.params import ParlaiParser\n",
    "from parlai.agents.repeat_label.repeat_label import RepeatLabelAgent\n",
    "from parlai.core.worlds import create_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\"-t\", \"convai2\"]\n",
    "parser = ParlaiParser()\n",
    "parser.add_argument(\"-n\", \"--num-examples\", default=5, type=int)\n",
    "opt = parser.parse_args(args)  # special parlai Opt class, seem to be like a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = RepeatLabelAgent(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worlds\n",
    "* https://parl.ai/docs/tutorial_worlds.html\n",
    "* https://github.com/facebookresearch/ParlAI/blob/master/parlai/core/worlds.py\n",
    "\n",
    "world.parley():   Agent 0 goes first.  Alternate between the two agents.\n",
    "\n",
    "BathWorlds:\n",
    "\n",
    "pseudocode in DialogPartnerWorld\n",
    "\n",
    "```\n",
    "query = teacher.act()\n",
    "student.observe(query)\n",
    "reply = student.act()\n",
    "teacher.observe(reply)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:09:55 | creating task(s): convai2\n",
      "17:09:55 | loading fbdialog data: /home/erik/miniconda3/envs/ttd/lib/python3.8/site-packages/data/ConvAI2/train_self_original.txt\n",
      "Agent 0: DefaultTeacher\n",
      "Agent 1: RepeatLabelAgent\n"
     ]
    }
   ],
   "source": [
    "world = create_task(opt, agent)  # DialogPartnerWorld\n",
    "for i, agent in enumerate(world.agents):\n",
    "    print(f\"Agent {i}:\", agent.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[convai2]:\u001b[0;0m \u001b[1myour persona: i want to be in a band someday.\n",
      "your persona: i've a wife and two kids.\n",
      "your persona: my hobbies are sleeping and playing the guitar.\n",
      "your persona: i sleep 10 hours every day because my work is tiring.\n",
      "your persona: i am a factory worker.\n",
      "__SILENCE__\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mhi , how are you today\u001b[0;0m\n",
      "   \u001b[0;34m[RepeatLabelAgent]:\u001b[0;0m \u001b[1;94mhi , how are you today\u001b[0;0m\n",
      "\n",
      "\u001b[0;34m[convai2]:\u001b[0;0m \u001b[1mi am fine , how are you today ?\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mi need a nap , i love sleeping it is a hobby !\u001b[0;0m\n",
      "   \u001b[0;34m[RepeatLabelAgent]:\u001b[0;0m \u001b[1;94mi need a nap , i love sleeping it is a hobby !\u001b[0;0m\n",
      "\n",
      "\u001b[0;34m[convai2]:\u001b[0;0m \u001b[1mi love to nap , i need it after my long shifts . what do you do for work ?\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mi'm tried from work , i work in a factory so that is hard work .\u001b[0;0m\n",
      "   \u001b[0;34m[RepeatLabelAgent]:\u001b[0;0m \u001b[1;94mi'm tried from work , i work in a factory so that is hard work .\u001b[0;0m\n",
      "\n",
      "\u001b[0;34m[convai2]:\u001b[0;0m \u001b[1mi work as a paramedic , so we get a lot of stress on the job .\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mbut one day i will be in a rock band , that's my dream !\u001b[0;0m\n",
      "   \u001b[0;34m[RepeatLabelAgent]:\u001b[0;0m \u001b[1;94mbut one day i will be in a rock band , that's my dream !\u001b[0;0m\n",
      "\n",
      "\u001b[0;34m[convai2]:\u001b[0;0m \u001b[1mof all the bands , the beatles are my favorite . are you like them ?\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mparamedic , that sound cool and interesting .\u001b[0;0m\n",
      "   \u001b[0;34m[RepeatLabelAgent]:\u001b[0;0m \u001b[1;94mparamedic , that sound cool and interesting .\u001b[0;0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(opt[\"num_examples\"]):\n",
    "    world.parley()\n",
    "    print(world.display() + \"\\n\")\n",
    "    if world.epoch_done():\n",
    "        print(\"epoch done\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Agent\n",
    "\n",
    "We follow the example given in \n",
    "\n",
    "https://parl.ai/docs/tutorial_torch_generator_agent.html#tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchGeneratorAgent\n",
    "import parlai.core.torch_generator_agent as tga\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "Extends tga.TorchGeneratorModel which is simply a wrapper/extension of the regular nn.Module class from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenModel(tga.TorchGeneratorModel):\n",
    "    def __init__(self, dictionary, hidden_size=256):\n",
    "        super().__init__(\n",
    "            padding_idx=dictionary[\"padding_idx\"],\n",
    "            start_idx=dictionary[\"start_idx\"],\n",
    "            end_idx=dictionary[\"end_idx\"],\n",
    "            unknown_idx=dictionary[\"unknown_idx\"],\n",
    "        )\n",
    "        self.embeddings = nn.Embedding(len(dictionary), hidden_size)\n",
    "        self.encoder = Encoder(self.embeddings, hidden_size)\n",
    "        self.decoder = Decoder(self.embeddings, hidden_size)\n",
    "\n",
    "    def output(self, decoder_output):\n",
    "        return F.linear(decoder_output, self.embeddings.weight)\n",
    "\n",
    "    def reorder_encoder_states(self, encoder_states, indices):\n",
    "        h, c = encoder_states\n",
    "        return h[:, indices, :], c[:, indices, :]\n",
    "\n",
    "    def reorder_decoder_incremental_state(self, incr_state, indices):\n",
    "        h, c = incr_state\n",
    "        return h[:, indices, :], c[:, indices, :]\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embeddings, hidden_size):\n",
    "        super().__init__()\n",
    "        _vocab_size, esz = embeddings.weight.shape\n",
    "        self.embeddings = embeddings\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=esz, hidden_size=hidden_size, num_layers=1, batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, input_tokens):\n",
    "        embedded = self.embeddings(input_tokens)\n",
    "        _output, hidden = self.lstm(embedded)\n",
    "        return hidden\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, embeddings, hidden_size):\n",
    "        super().__init__()\n",
    "        _vocab_size, self.esz = embeddings.weight.shape\n",
    "        self.embeddings = embeddings\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.esz, hidden_size=hidden_size, num_layers=1, batch_first=True\n",
    "        )\n",
    "\n",
    "    def forward(self, input, encoder_state, incr_state=None):\n",
    "        embedded = self.embeddings(input)\n",
    "        if incr_state is None:\n",
    "            state = encoder_state\n",
    "        else:\n",
    "            state = incr_state\n",
    "        output, incr_state = self.lstm(embedded, state)\n",
    "        return output, incr_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent\n",
    "\n",
    "Now we extend the class tga.TorchGeneratorAgent in a way such that it uses our PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGenAgent(tga.TorchGeneratorAgent):\n",
    "    @classmethod\n",
    "    def add_cmdline_args(cls, argparser):\n",
    "        super(CustomGenAgent, cls).add_cmdline_args(argparser)\n",
    "        group = argparser.add_argument_group(\"Example TGA Agent\")\n",
    "        group.add_argument(\n",
    "            \"-hid\", \"--hidden-size\", type=int, default=256, help=\"Hidden size.\"\n",
    "        )\n",
    "\n",
    "    def build_model(self):\n",
    "        model = GenModel(self.dict, self.opt[\"hidden_size\"])\n",
    "        if self.opt[\"embedding_type\"] != \"random\":\n",
    "            self._copy_embeddings(model.embeddings.weight, self.opt[\"embedding_type\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to use our custom agent instead of the simple `RepeatLabelAgent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:17:55 | Using CUDA\n",
      "17:17:55 | Total parameters: 1,053,696 (1,053,696 trainable)\n",
      "17:17:55 | creating task(s): convai2\n",
      "17:17:55 | loading fbdialog data: /home/erik/miniconda3/envs/ttd/lib/python3.8/site-packages/data/ConvAI2/train_self_original.txt\n",
      "\n",
      "Agent 0: DefaultTeacher\n",
      "Agent 1: CustomGenAgent\n",
      "==================================================\n",
      "model:  GenModel(\n",
      "  (embeddings): Embedding(4, 256)\n",
      "  (encoder): Encoder(\n",
      "    (embeddings): Embedding(4, 256)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embeddings): Embedding(4, 256)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "  )\n",
      ")\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Get the opts\n",
    "args = [\"-t\", \"convai2\"]\n",
    "# args = [\"-t\", \"dailydialog\"]\n",
    "parser = ParlaiParser()\n",
    "CustomGenAgent.add_cmdline_args(parser)\n",
    "parser.add_argument(\"-n\", \"--num-examples\", default=5, type=int)\n",
    "opt = parser.parse_args(args)  # special parlai Opt class, seem to be like a dict\n",
    "\n",
    "\n",
    "# Create agent\n",
    "agent = CustomGenAgent(opt)\n",
    "\n",
    "# Show the agents of the world and task\n",
    "world = create_task(opt, agent)  # DialogPartnerWorld\n",
    "print()\n",
    "for i, agent in enumerate(world.agents):\n",
    "    print(f\"Agent {i}:\", agent.__class__.__name__)\n",
    "    if hasattr(agent, \"model\"):\n",
    "        print('='*50)\n",
    "        print(\"model: \", agent.model)\n",
    "        print('='*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets run world.parley() again to see how it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent.observation: BEFORE {'text': 'your persona: my favorite thing to do is float the river.\\nyour persona: my favorite activity is fishing.\\nyour persona: i once ran the mile in under 4 minutes.\\nyour persona: i cannot go a single day without eating ice cream.\\nhi ! i am jovanni . whats up ? tell me about yourself .', 'labels': ['i wo not be doing any floating in the river this weekend . darn irma .'], 'reward': 0, 'label_candidates': ['hi ! good because i played hooky today . . . just baking my fave brownies today . you ?', \"that's not fun , i hope things work out\", 'are you the lady i gave my number to last night ?', 'thank you , i feel the same way', 'no bacon for me but i love chocolate milkshakes', 'yes i have both red and black', 'oh right yes . probably the same from batman .', 'i go to spas and hang out with my dog .', 'sounds like a lot of fun !', 'yes . i can make anyone look pretty', 'i sing opera , and boil pasta . my dog is my only friend . what can we do ?', 'do you run far distances ?', 'the most freeing experience is nature . just the sounds a lone are music', 'sounds like a good way to start the weekend . what are you studying ?', 'what kind of seafood do you like ?', 'i bet , i am glad i always had a little something saved away from her !', 'o okay you are very young', 'what other things are you into ?', 'hello and how are you today ?', 'i wo not be doing any floating in the river this weekend . darn irma .'], 'episode_done': False, 'id': 'convai2', 'full_text': 'your persona: my favorite thing to do is float the river.\\nyour persona: my favorite activity is fishing.\\nyour persona: i once ran the mile in under 4 minutes.\\nyour persona: i cannot go a single day without eating ice cream.\\nhi ! i am jovanni . whats up ? tell me about yourself .', 'text_vec': tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]), 'full_text_vec': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'labels_vec': tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2]), 'labels_choice': 'i wo not be doing any floating in the river this weekend . darn irma .'}\n",
      "\n",
      "\n",
      "agent.observation AFTER:  {'text': 'your persona: my favorite thing to do is float the river.\\nyour persona: my favorite activity is fishing.\\nyour persona: i once ran the mile in under 4 minutes.\\nyour persona: i cannot go a single day without eating ice cream.\\nhi ! i am jovanni . whats up ? tell me about yourself .', 'labels': ['i wo not be doing any floating in the river this weekend . darn irma .'], 'reward': 0, 'label_candidates': ['hi ! good because i played hooky today . . . just baking my fave brownies today . you ?', \"that's not fun , i hope things work out\", 'are you the lady i gave my number to last night ?', 'thank you , i feel the same way', 'no bacon for me but i love chocolate milkshakes', 'yes i have both red and black', 'oh right yes . probably the same from batman .', 'i go to spas and hang out with my dog .', 'sounds like a lot of fun !', 'yes . i can make anyone look pretty', 'i sing opera , and boil pasta . my dog is my only friend . what can we do ?', 'do you run far distances ?', 'the most freeing experience is nature . just the sounds a lone are music', 'sounds like a good way to start the weekend . what are you studying ?', 'what kind of seafood do you like ?', 'i bet , i am glad i always had a little something saved away from her !', 'o okay you are very young', 'what other things are you into ?', 'hello and how are you today ?', 'i wo not be doing any floating in the river this weekend . darn irma .'], 'episode_done': False, 'id': 'convai2', 'full_text': 'your persona: my favorite thing to do is float the river.\\nyour persona: my favorite activity is fishing.\\nyour persona: i once ran the mile in under 4 minutes.\\nyour persona: i cannot go a single day without eating ice cream.\\nhi ! i am jovanni . whats up ? tell me about yourself .', 'text_vec': tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]), 'full_text_vec': [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3], 'labels_vec': tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2]), 'labels_choice': 'i wo not be doing any floating in the river this weekend . darn irma .'}\n"
     ]
    }
   ],
   "source": [
    "print(\"agent.observation: BEFORE\", agent.observation)\n",
    "try:\n",
    "    for i in range(opt[\"num_examples\"]):\n",
    "        world.parley()\n",
    "        print(world.display() + \"\\n\")\n",
    "        if world.epoch_done():\n",
    "            print(\"epoch done\")\n",
    "            break\n",
    "except:\n",
    "    pass\n",
    "            \n",
    "print(\"\\n\\nagent.observation AFTER: \", agent.observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assertion Error\n",
    "The model checks that the first tokens are correct (not multiple bos-tokens) and it fails. Throwing this error:\n",
    "\n",
    "```\n",
    "AssertionError: The Beginning of Sentence token is automatically added to the label in decode_forced, but you included it in the label. This means your model will have a double BOS token, which is probably not what you intended.\n",
    "```\n",
    "\n",
    "We can see from our agents observations that all text got mapped onto the same symbol (probably unk-token??). So the tokenization is not handled correct for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "ParlAI does a good job abstracting a way the notion of a tokenizer. It is somewhat difficult to find where and how the tokenizer is used but you'll soon end up on `DictionaryAgent`.\n",
    "\n",
    "\n",
    "The DictionaryAgent handles the process of turning text into vectors and back... Our lookup table / vocab. In my work I want to be able to use pretrained tokenizers from the huggingface framwork but also remove capitalization and punctuation, making the text more simliar to that of spoken dialog interaction, and so we are going to implement our own DictionaryAgent based on information found in the ParlAI transformer code.\n",
    "\n",
    "Im going to use a normalizer from the HuggingFace Tokenizer library (fast tokenization written in rust) to remove punctuation and capitalization but then feed that text into some pretrained tokenizer (i.e. Bert, GPT2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Tokenizer\n",
    "from parlai.core.dict import DictionaryAgent\n",
    "from transformers import AutoTokenizer\n",
    "from parlai.utils.misc import warn_once\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers import pre_tokenizers, normalizers, decoders, Regex\n",
    "from tokenizers.normalizers import Lowercase, NFD, StripAccents, Replace, Strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpokenDialogDictionaryAgent(DictionaryAgent):\n",
    "    \"\"\"\n",
    "    Allow to use the Torch Agent with the wordpiece dictionary of Hugging Face.\n",
    "    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def add_cmdline_args(cls, argparser):\n",
    "        argparser.add_argument(\"--tokenizer\", type=str, default=\"gpt2\")\n",
    "\n",
    "    @staticmethod\n",
    "    def build_normalizer():\n",
    "        normalizer = normalizers.Sequence(\n",
    "            [\n",
    "                NFD(),\n",
    "                Lowercase(),\n",
    "                StripAccents(),\n",
    "                Replace(Regex('[\\.\\,\\!\\?\\:\\;\\)\\(\\[\\]\"\\-]'), \"\"),\n",
    "                Strip(),\n",
    "            ]\n",
    "        )\n",
    "        return normalizer\n",
    "\n",
    "    def __init__(self, opt):\n",
    "        # initialize from vocab path\n",
    "        warn_once(\n",
    "            \"WARNING: TurnTaking uses a TurnTaking tokenizer; ParlAI dictionary args are ignored\"\n",
    "        )\n",
    "        # download(opt[\"datapath\"])\n",
    "        self._tokenizer = AutoTokenizer.from_pretrained(opt[\"tokenizer\"])\n",
    "        self.normalizer = SpokenDialogDictionaryAgent.build_normalizer()\n",
    "        super().__init__(opt)\n",
    "\n",
    "        if opt[\"tokenizer\"].startswith(\"gpt2\"):\n",
    "            self.start_token = \"[CLS]\"\n",
    "            self.cls_token = \"[CLS]\"\n",
    "            self.end_token = \"[SEP]\"\n",
    "            self.pad_token = \"[PAD]\"\n",
    "            self.null_token = \"[PAD]\"\n",
    "            self.mask_token = \"[MASK]\"\n",
    "            self.unk_token = \"[UNK]\"\n",
    "        elif opt[\"tokenizer\"].startswith(\"bert\"):\n",
    "            self.start_token = \"[bos\"\n",
    "            self.end_token = \"[SEP]\"\n",
    "            self.pad_token = \"<end-of-text>\"\n",
    "            self.null_token = \"<end-of-text>\"\n",
    "            self.mask_token = \"[MASK]\"\n",
    "            self.unk_token = \"[UNK]\"\n",
    "\n",
    "        self.start_idx = self._tokenizer.convert_tokens_to_ids(self.start_token)\n",
    "        self.end_idx = self._tokenizer.convert_tokens_to_ids(self.end_token)\n",
    "        self.pad_idx = self._tokenizer.convert_tokens_to_ids(self.pad_token)\n",
    "        self.unk_idx = self._tokenizer.convert_tokens_to_ids(self.unk_token)\n",
    "        self.null_idx = self._tokenizer.convert_tokens_to_ids(self.null_token)\n",
    "\n",
    "        self.update_vocab()\n",
    "\n",
    "    def update_vocab(self):\n",
    "        # set tok2ind for special tokens\n",
    "        self.tok2ind[self.start_token] = self.start_idx\n",
    "        self.tok2ind[self.end_token] = self.end_idx\n",
    "        self.tok2ind[self.pad_token] = self.pad_idx\n",
    "        self.tok2ind[self.unk_token] = self.unk_idx\n",
    "\n",
    "        # set ind2tok for special tokens\n",
    "        self.ind2tok[self.start_idx] = self.start_token\n",
    "        self.ind2tok[self.end_idx] = self.end_token\n",
    "        self.ind2tok[self.pad_idx] = self.null_token\n",
    "        self.ind2tok[self.unk_idx] = self.unk_token\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._tokenizer)\n",
    "\n",
    "    def encode(self, text, add_special_tokens=False):\n",
    "        text = self.normalizer.normalize_str(text)\n",
    "        return self._tokenizer.encode(text, add_special_tokens=add_special_tokens)\n",
    "\n",
    "    def txt2vec(self, text, vec_type=list):\n",
    "        return self.encode(text)\n",
    "\n",
    "    def vec2txt(self, vec):\n",
    "        if not isinstance(vec, list):\n",
    "            # assume tensor\n",
    "            vec = vec.tolist()\n",
    "        return self._tokenizer.decode(vec)\n",
    "\n",
    "    def act(self):\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update our Agent class\n",
    "\n",
    "Now we also must update our agent class to tell it which DictionaryAgent it should rely on. This is easily done by overwriting a function in the agent class namely `dictionary_class()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomGenAgent(tga.TorchGeneratorAgent):\n",
    "    @classmethod\n",
    "    def add_cmdline_args(cls, argparser):\n",
    "        argparser.set_defaults(dict_maxexs=0)  # skip building dictionary)\n",
    "        super(CustomGenAgent, cls).add_cmdline_args(argparser)\n",
    "        cls.dictionary_class().add_cmdline_args(argparser)\n",
    "        group = argparser.add_argument_group(\"Example TGA Agent\")\n",
    "        group.add_argument(\n",
    "            \"-hid\", \"--hidden-size\", type=int, default=256, help=\"Hidden size.\"\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def dictionary_class():\n",
    "        \"\"\"\n",
    "        Return the dictionary class that this agent expects to use.\n",
    "\n",
    "        Can be overriden if a more complex dictionary is required.\n",
    "        \"\"\"\n",
    "        return SpokenDialogDictionaryAgent\n",
    "\n",
    "    def build_model(self):\n",
    "        model = GenModel(self.dict, self.opt[\"hidden_size\"])\n",
    "        if self.opt[\"embedding_type\"] != \"random\":\n",
    "            self._copy_embeddings(model.embeddings.weight, self.opt[\"embedding_type\"])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer:  gpt2\n"
     ]
    }
   ],
   "source": [
    "# Create agent\n",
    "parser = ParlaiParser()\n",
    "CustomGenAgent.add_cmdline_args(parser)\n",
    "parser.add_argument(\"-n\", \"--num-examples\", default=5, type=int)\n",
    "opt = parser.parse_args(args)  # special parlai Opt class, seem to be like a dict\n",
    "print('tokenizer: ', opt['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17:38:23 | Using CUDA\n",
      "17:38:25 | Total parameters: 13,918,464 (13,918,464 trainable)\n",
      "17:38:25 | creating task(s): convai2\n",
      "17:38:25 | loading fbdialog data: /home/erik/miniconda3/envs/ttd/lib/python3.8/site-packages/data/ConvAI2/train_self_original.txt\n",
      "\n",
      "Agent 0: DefaultTeacher\n",
      "Agent 1: CustomGenAgent\n",
      "==================================================\n",
      "model:  GenModel(\n",
      "  (embeddings): Embedding(50257, 256)\n",
      "  (encoder): Encoder(\n",
      "    (embeddings): Embedding(50257, 256)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embeddings): Embedding(50257, 256)\n",
      "    (lstm): LSTM(256, 256, batch_first=True)\n",
      "  )\n",
      ")\n",
      "==================================================\n",
      "\n",
      "agent.observation:  None\n",
      "\u001b[0;34m[convai2]:\u001b[0;0m \u001b[1myour persona: i have never broken a bone.\n",
      "your persona: i love cats.\n",
      "your persona: i am a freshman in college.\n",
      "your persona: i am athletic.\n",
      "your persona: my favorite food is pizza.\n",
      "hello , how are you doing today ?\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mi am good especially because my cat is cuddling with me ! you ?\u001b[0;0m\n",
      "\n",
      "\u001b[0;34m[convai2]:\u001b[0;0m \u001b[1mi wish i had a cat . i only have children haha .\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mcool , its my first year in college and i'm pretty athletic .\u001b[0;0m\n",
      "\n",
      "\u001b[0;34m[convai2]:\u001b[0;0m \u001b[1mwhat kind of sports do you play ?\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mi swim , i am good at it because my bones have never broke !\u001b[0;0m\n",
      "\n",
      "\u001b[0;34m[convai2]:\u001b[0;0m \u001b[1mi have never broken a bone either . ever thought about going to mars ?\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94myes , do you plan on going ?\u001b[0;0m\n",
      "\n",
      "\u001b[0;34m[convai2]:\u001b[0;0m \u001b[1mi would love to go some day !\u001b[0;0m\n",
      "\u001b[0;34m[labels]:\u001b[0;0m \u001b[1;94mi love pizza , do you think there's any there ?\u001b[0;0m\n",
      "\n",
      "agent.observation:  {'text': 'i would love to go some day !', 'labels': [\"i love pizza , do you think there's any there ?\"], 'reward': 0, 'label_candidates': ['i wanted it all ! i became a minimalist and am now president .', 'how cold is it right now ?', 'skateboarder man ! tony hawk is my hero ! !', \"well i've an mba but i don't need it anymore . what do you do ?\", \"oh . i've black hair , what color is yours ?\", 'sounds heavy . what kind of toppings ?', \"do you still drink a lot ? i don't drink at all .\", \"yeah , i like movies . i go all the time with all the friends i've .\", \"sure i'm planning a party for my birthday .\", 'not all all . everyone has their own preferences . i mean i read fan fiction .', 'do you like the cowboys ? dude , i sure do .', 'maybe i will , not sure if you can become a pilot after lasik , i will check', 'my dad hate at times cause she have fun he a tax assessor', 'do you have friends or family you can talk to ?', 'dogs are very special indeed', \"wow . have you done it long ? what will you do with retirement ? i'm not there yet .\", 'i do small murals . but i would like to work on something bigger .', 'hi how are you today', 'where did you go to school ?', \"i love pizza , do you think there's any there ?\"], 'episode_done': False, 'id': 'convai2', 'full_text': \"your persona: i have never broken a bone.\\nyour persona: i love cats.\\nyour persona: i am a freshman in college.\\nyour persona: i am athletic.\\nyour persona: my favorite food is pizza.\\nhello , how are you doing today ?\\ni am good especially because my cat is cuddling with me ! you ?\\ni wish i had a cat . i only have children haha .\\ncool , its my first year in college and i'm pretty athletic .\\nwhat kind of sports do you play ?\\ni swim , i am good at it because my bones have never broke !\\ni have never broken a bone either . ever thought about going to mars ?\\nyes , do you plan on going ?\\ni would love to go some day !\", 'text_vec': tensor([14108, 27822,  1312,   423,  1239,  5445,   257,  9970,   198, 14108,\n",
      "        27822,  1312,  1842, 11875,   198, 14108, 27822,  1312,   716,   257,\n",
      "        18621,   287,  4152,   198, 14108, 27822,  1312,   716, 15177,   198,\n",
      "        14108, 27822,   616,  4004,  2057,   318, 14256,   198, 31373,   220,\n",
      "          703,   389,   345,  1804,  1909,    72,   716,   922,  2592,   780,\n",
      "          616,  3797,   318,   269,  4185,  1359,   351,   502,   220,   345,\n",
      "           72,  4601,  1312,   550,   257,  3797,   220,  1312,   691,   423,\n",
      "         1751, 42254, 24494,   220,   663,   616,   717,   614,   287,  4152,\n",
      "          290,  1312,  1101,  2495, 15177, 10919,  1611,   286,  5701,   466,\n",
      "          345,   711,    72,  9422,   220,  1312,   716,   922,   379,   340,\n",
      "          780,   616, 11945,   423,  1239,  6265,    72,   423,  1239,  5445,\n",
      "          257,  9970,  2035,   220,  1683,  1807,   546,  1016,   284, 48962,\n",
      "         8505,   220,   466,   345,  1410,   319,  1016,    72,   561,  1842,\n",
      "          284,   467,   617,  1110]), 'full_text_vec': [14108, 27822, 1312, 423, 1239, 5445, 257, 9970, 198, 14108, 27822, 1312, 1842, 11875, 198, 14108, 27822, 1312, 716, 257, 18621, 287, 4152, 198, 14108, 27822, 1312, 716, 15177, 198, 14108, 27822, 616, 4004, 2057, 318, 14256, 198, 31373, 220, 703, 389, 345, 1804, 1909, 72, 716, 922, 2592, 780, 616, 3797, 318, 269, 4185, 1359, 351, 502, 220, 345, 72, 4601, 1312, 550, 257, 3797, 220, 1312, 691, 423, 1751, 42254, 24494, 220, 663, 616, 717, 614, 287, 4152, 290, 1312, 1101, 2495, 15177, 10919, 1611, 286, 5701, 466, 345, 711, 72, 9422, 220, 1312, 716, 922, 379, 340, 780, 616, 11945, 423, 1239, 6265, 72, 423, 1239, 5445, 257, 9970, 2035, 220, 1683, 1807, 546, 1016, 284, 48962, 8505, 220, 466, 345, 1410, 319, 1016, 72, 561, 1842, 284, 467, 617, 1110], 'labels_vec': tensor([   72,  1842, 14256,   220,   466,   345,   892,   612,   338,   597,\n",
      "          612, 50256]), 'labels_choice': \"i love pizza , do you think there's any there ?\"}\n"
     ]
    }
   ],
   "source": [
    "agent = CustomGenAgent(opt)\n",
    "world = create_task(opt, agent)  # DialogPartnerWorld\n",
    "\n",
    "# Show the agents of the world and task\n",
    "print()\n",
    "for i, agent in enumerate(world.agents):\n",
    "    print(f\"Agent {i}:\", agent.__class__.__name__)\n",
    "    if hasattr(agent, \"model\"):\n",
    "        print('='*50)\n",
    "        print(\"model: \", agent.model)\n",
    "        print('='*50)\n",
    "        \n",
    "print()\n",
    "print(\"agent.observation: \", agent.observation)\n",
    "for i in range(opt[\"num_examples\"]):\n",
    "    world.parley()\n",
    "    print(world.display() + \"\\n\")\n",
    "    if world.epoch_done():\n",
    "        print(\"epoch done\")\n",
    "        break\n",
    "print(\"agent.observation: \", agent.observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It Works!\n",
    "\n",
    "So now the agent uses a correctly defined DictionaryAgent and we can see that the text have been encoded correctly. The DictionaryAgent can be accessed by `agent.dict`. Lets see how the text is changed between encoding and decoding (because of our custom normalizer).\n",
    "\n",
    "\n",
    "So we are now a step closer in being able to train our own model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i would love to go some day !\n",
      "vec:  [72, 561, 1842, 284, 467, 617, 1110]\n",
      "decoded text:  i would love to go some day\n"
     ]
    }
   ],
   "source": [
    "print(agent.observation['text'])\n",
    "vec = agent.dict.txt2vec(agent.observation['text'])\n",
    "print('vec: ', vec)\n",
    "txt = agent.dict.vec2txt(vec)\n",
    "print('decoded text: ', txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see all the words gets remapped correctly except the exclamation point (as desired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
